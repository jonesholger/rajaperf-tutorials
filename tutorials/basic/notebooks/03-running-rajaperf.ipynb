{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Running RAJAPerf \n",
    "\n",
    "In this section we will be running RAJAPerf, exploring some of the properties of a set of kernels that belong to a group,  \n",
    "demonstrating several techniques to display the timing Hierarchy, and creating basic bar graphs for comparisons of   \n",
    "timing using compilers GCC vs Clang.\n",
    "\n",
    "[Back to Table of Contents](./00-intro-and-contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic help text\n",
    "Running raja-perf.exe --help shows how we can control the performance run.\n",
    "For this notebook section we mainly modulate the number of reps, while in\n",
    "the next section we will change the focus to capture runs with varying \n",
    "problem size.\n",
    "\n",
    "Note that several cells in this section are setup as bash command line, \n",
    "however you can switch to a terminal session under the Jupyter launcher \n",
    "and run the same commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "$HOME/code/RAJAPerf/build_gcc/bin/raja-perf.exe --help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## RAJAPerf dryrun\n",
    "First lets run RAJAPerf, performing a dryrun and looking at the run properties, paying particular \n",
    "attention to the default Problem size, and Reps. We're also just going to specify one group of \n",
    "kernels to run, in this case they all fall into the Algorithm group.\n",
    "\n",
    "To see the full list of kernels edit the command by removing the --kernels Algorithm argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "$HOME/code/RAJAPerf/build_gcc/bin/raja-perf.exe --dryrun --kernels Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## RAJAPerf run with one rep on group Algorithm\n",
    "Next lets actually generate output, but we'll pass in the argument --checkrun 1 \n",
    "to just run one rep of all the kernels in group Algorithm, we do this so the \n",
    "output is generated very quickly.\n",
    "\n",
    "We also specify the -sp flag to show progress timing the kernels\n",
    "\n",
    "Note that RAJAPerf runs a bunch of warmup kernels. These are not included in \n",
    "the output data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "$HOME/code/RAJAPerf/build_gcc/bin/raja-perf.exe -od $HOME/data/default_problem_size/gcc --checkrun 1 --kernels Algorithm -sp\n",
    "ls $HOME/data/default_problem_size/gcc/*.cali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inspect Timing Hierachy using Caliper's cali-query tool\n",
    "Next let's inspect the files created by running RAJAPerf. In addition to the .txt and .csv files,\n",
    "we also output a set of Caliper data .cali. \n",
    "\n",
    "We're going to show several techniques to display the Caliper trees (Timing Hierarchy)\n",
    "\n",
    "The first technique is with Caliper's own tool cali-query, we run it with -T to display tree, \n",
    "or you can specify --tree. We'll focus on inspecting the timing generated by running RAJA with\n",
    "execution policy sequential, RAJA_Seq.cali\n",
    "\n",
    "Since we installed RAJAPerf using Spack, we'll activate the environment containing the \n",
    "install, and load up the Caliper version installed in order to get cali-query on our PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "eval `spack env activate --sh  --dir /home/jovyan/spack_env`\n",
    "eval `$HOME/spack/bin/spack load --sh caliper@master%gcc@10.4.0`\n",
    "which cali-query\n",
    "cali-query -T $HOME/data/default_problem_size/gcc/RAJA_Seq.cali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inspect timing hierarchy using Caliper's Python module\n",
    "Next we inspect the .cali file with Caliper's own CaliperReader Python module \n",
    "It's a short python script\n",
    "\n",
    "You can add a couple of lines to view the metadata keys captured by Caliper/Adiak\n",
    "for g in r.globals:\n",
    "    print(g)\n",
    "\n",
    "You can also add a line to display metadata value in the dictionary r.globals\n",
    "We'll just print out the OpenMP Max Threads value recorded at runtime\n",
    "\n",
    "print('OMP Max Threads: ' + r.globals['omp_max_threads'])\n",
    "\n",
    "or the variant represented in this file\n",
    "print('Variant: ' + r.globals['variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import caliperreader as cr\n",
    "DATA_DIR = os.getenv('HOME')+\"/data/default_problem_size/gcc\"\n",
    "os.chdir(DATA_DIR)\n",
    "r = cr.CaliperReader()\n",
    "r.read(\"RAJA_Seq.cali\")\n",
    "metric = 'avg#inclusive#sum#time.duration'\n",
    "for rec in r.records:\n",
    "    path = rec['path'] if 'path' in rec else 'UNKNOWN'\n",
    "    time = rec[metric] if metric in rec else '0'\n",
    "    if not 'UNKNOWN' in path:\n",
    "        if (isinstance(path, list)):\n",
    "            path = \"/\".join(path)\n",
    "        print(\"{0}: {1}\".format(path, time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using Hatchet to inspect Caliper trees\n",
    "Finally we'll inspect Caliper trees using the Hatchet Python module which we already have installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import hatchet as ht\n",
    "DATA_DIR = os.getenv('HOME')+\"/data/default_problem_size/gcc\"\n",
    "os.chdir(DATA_DIR)\n",
    "gf1 = ht.GraphFrame.from_caliperreader(\"RAJA_Seq.cali\")\n",
    "print(gf1.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run RAJAPerf full pass for GCC and Clang\n",
    "Let's run the GCC/CLang versions of RAJAPerf, one full pass each, we'll perform a comparison plot in the next cell\n",
    "We'll save the outputs for each compiler in separate directories using the -od flag (output directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "$HOME/code/RAJAPerf/build_gcc/bin/raja-perf.exe -od $HOME/data/default_problem_size/gcc --checkrun 1 -sp\n",
    "$HOME/code/RAJAPerf/build_clang/bin/raja-perf.exe -od $HOME/data/default_problem_size/clang --checkrun 1 -sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate Bar graphs which compare the variants across the two different compilers\n",
    "We'll generate a multi-index based on the compilers and variants and generate\n",
    "a Pandas dataframe against that index, and plot it using built-in bargraph method\n",
    "\n",
    "The multi-index looks like\n",
    "MultiIndex([('clang++-9.0.1',   'Base_OpenMP'),\n",
    "            ('clang++-9.0.1',      'Base_Seq'),\n",
    "            ('clang++-9.0.1', 'Lambda_OpenMP'),\n",
    "            ('clang++-9.0.1',    'Lambda_Seq'),\n",
    "            ('clang++-9.0.1',   'RAJA_OpenMP'),\n",
    "            ('clang++-9.0.1',      'RAJA_Seq'),\n",
    "            (   'g++-10.4.0',   'Base_OpenMP'),\n",
    "            (   'g++-10.4.0',      'Base_Seq'),\n",
    "            (   'g++-10.4.0', 'Lambda_OpenMP'),\n",
    "            (   'g++-10.4.0',    'Lambda_Seq'),\n",
    "            (   'g++-10.4.0',   'RAJA_OpenMP'),\n",
    "            (   'g++-10.4.0',      'RAJA_Seq')],\n",
    "           names=['compiler', 'variant'])\n",
    "\n",
    "This really only works because we sorted the file list to process at the beginning\n",
    "and the multi-index sort order implicitly matches.\n",
    "\n",
    "Note also that we're building up data structures using Hatchet's reader method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob\n",
    "import hatchet as ht\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = os.getenv('HOME')+\"/data/default_problem_size/\"\n",
    "\n",
    "data = []\n",
    "allfiles = sorted(glob.glob(glob.escape(DATA_DIR) + \"*/*.cali\"))\n",
    "metric = 'avg#inclusive#sum#time.duration'\n",
    "for f in allfiles:\n",
    "    gf = ht.GraphFrame.from_caliperreader(f)\n",
    "    compiler = gf.metadata['compiler']\n",
    "    variant = gf.metadata['variant']\n",
    "    root_node = gf.graph.roots[0]\n",
    "    value = gf.dataframe.loc[root_node, metric]\n",
    "    data_tuple = tuple((compiler,variant,value))\n",
    "    data.append(data_tuple)\n",
    "compilers = sorted({d[0] for d in data})\n",
    "variants = sorted({v[1] for v in data})\n",
    "idx = pd.MultiIndex.from_product([compilers,variants],sortorder=1, names=['compiler', 'variant'])\n",
    "df = pd.DataFrame(data,index=idx,columns=['compiler','variant','value'])\n",
    "df.unstack(level=0)['value'].plot(kind='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
