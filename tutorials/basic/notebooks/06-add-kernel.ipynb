{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2018c0c-1dbc-4a5d-9d22-62b3bf4f40d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Adding a kernel to RAJAPerf \n",
    "\n",
    "In this section we will be adding a simple kernel to RAJAPerf, into a new group called tutorial with kernel name Tutorial_KERNEL. \n",
    "The tutorial uses several skeletal files for sequential and openmp, base and RAJA variants.\n",
    "The bulk of this notebook is to populate these skeletal files.\n",
    "\n",
    "We will compile and run them using the same charting techniques we demonstrated earlier in a subsequent notebook.\n",
    "\n",
    "[Back to Table of Contents](./00-intro-and-contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78ec08-d685-46a6-9725-2c98447fc73c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Always run the following cell to init/reinit notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b21b7-c0dd-4f19-ac59-3e2445250d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"/opt/conda/include/\")\n",
    "#pragma cling add_library_path(\"/opt/conda/lib/\")\n",
    "#pragma cling load(\"libomp\")\n",
    "\n",
    "#pragma cling add_include_path(\"/home/jovyan/spack/opt/spack/linux-ubuntu22.04-x86_64/gcc-10.4.0/camp-2022.03.2-nh5kkatqzxgiwxusi4ddpyhf2zcqxyow/include/\")\n",
    "#pragma cling add_include_path(\"/home/jovyan/spack/opt/spack/linux-ubuntu22.04-x86_64/gcc-10.4.0/raja-2022.03.0-f7p4trkfeq4gcmqnt5623haejgcvwlvl/include/\")\n",
    "#pragma cling add_library_path(\"/home/jovyan/spack/opt/spack/linux-ubuntu22.04-x86_64/gcc-10.4.0/raja-2022.03.0-f7p4trkfeq4gcmqnt5623haejgcvwlvl/lib/\")\n",
    "#pragma cling load(\"libRAJA\")\n",
    "\n",
    "#pragma cling add_include_path(\"/home/jovyan/code/RAJAPerf/build_gcc/include/\")\n",
    "#pragma cling add_include_path(\"/home/jovyan/code/RAJAPerf/src/\")\n",
    "#pragma cling add_library_path(\"/home/jovyan/code/RAJAPerf/build_gcc/lib/\")\n",
    "#pragma cling load(\"libcommon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9df9fb-a868-4e43-a4ee-a99db6f9d16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introducing Polybench Covariance kernel as our surrogate\n",
    "\n",
    "Using version 4 of the kernel\n",
    "```\n",
    "static\n",
    "void kernel_covariance(int m, int n,\n",
    "\t\t       DATA_TYPE float_n,\n",
    "\t\t       DATA_TYPE POLYBENCH_2D(data,M,N,m,n),\n",
    "\t\t       DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m),\n",
    "\t\t       DATA_TYPE POLYBENCH_1D(mean,M,m))\n",
    "{\n",
    "  int i, j, k;\n",
    "#pragma scop\n",
    "  for (j = 0; j < _PB_M; j++)\n",
    "    {\n",
    "      mean[j] = SCALAR_VAL(0.0);\n",
    "      for (i = 0; i < _PB_N; i++)\n",
    "        mean[j] += data[i][j];\n",
    "      mean[j] /= float_n;\n",
    "    }\n",
    "\n",
    "  for (i = 0; i < _PB_N; i++)\n",
    "    for (j = 0; j < _PB_M; j++)\n",
    "      data[i][j] -= mean[j];\n",
    "\n",
    "  for (i = 0; i < _PB_M; i++)\n",
    "    for (j = i; j < _PB_M; j++)\n",
    "      {\n",
    "        cov[i][j] = SCALAR_VAL(0.0);\n",
    "        for (k = 0; k < _PB_N; k++)\n",
    "\t  cov[i][j] += data[k][i] * data[k][j];\n",
    "        cov[i][j] /= (float_n - SCALAR_VAL(1.0));\n",
    "        cov[j][i] = cov[i][j];\n",
    "      }\n",
    "#pragma endscop\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52a28e-87e6-4e08-aef0-15aa11b3f973",
   "metadata": {},
   "source": [
    "## create macros for loop bodies\n",
    "We'll use relative indexing, since we're using Real_ptr vs actual Matrices\n",
    "For consistency we'll use i,j,k = M,N,M index spaces in all the variants below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ad794-7406-4edc-be33-33fc7dc23365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "// this is going into the header for the kernel\n",
    "#define POLYBENCH_VAR_BODY0 \\\n",
    "  mean[i] = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY1 \\\n",
    "  mean[i] += ldata[(j*m)+i];\n",
    "\n",
    "#define POLYBENCH_VAR_BODY2 \\\n",
    "  mean[i] /= float_n;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY3 \\\n",
    "  ldata[(j*m)+i] -= mean[j];\n",
    "\n",
    "#define POLYBENCH_VAR_BODY4 \\\n",
    "  symmat[(i*m)+k] = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY5 \\\n",
    "  symmat[(i*m)+k] += ldata[(j*m)+i] * ldata[(j*m)+k];\n",
    "\n",
    "#define POLYBENCH_VAR_BODY6 \\\n",
    "  symmat[(i*m)+k] /= (float_n - 1.0); \\\n",
    "  symmat[(k*m)+i] = symmat[(i*m)+k];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec0328-742e-475b-a7a6-9498bc26e9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "const int M = 2;\n",
    "const int N = 4;\n",
    "rajaperf::Real_ptr g_data;\n",
    "rajaperf::Real_ptr g_mean;\n",
    "rajaperf::Real_ptr g_symmat;\n",
    "rajaperf::detail::resetDataInitCount();\n",
    "rajaperf::detail::allocAndInitDataRandSign(g_data,N*M,RAJA::DATA_ALIGN,(rajaperf::VariantID)0);\n",
    "rajaperf::detail::allocAndInitDataConst(g_mean,M,RAJA::DATA_ALIGN,0.0,(rajaperf::VariantID)0);\n",
    "rajaperf::detail::allocAndInitDataConst(g_symmat,M*M,RAJA::DATA_ALIGN,0.0,(rajaperf::VariantID)0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34a8f1-bab5-4075-ada3-b0ff9f6f7d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "// let's create a pure sequential kernel for now to check what the output looks like\n",
    "// Note by default we create 1d index spaces but later we'll setup RAJA views to index 2d\n",
    "void kernel_cov(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "  int i, j, k;\n",
    "\n",
    "  int _PB_M = m;\n",
    "  int _PB_N = n;\n",
    "  double float_n = n;\n",
    "  \n",
    "  rajaperf::Real_ptr ldata;\n",
    "  rajaperf::detail::allocData(ldata,n*m,RAJA::DATA_ALIGN,(rajaperf::VariantID)0);\n",
    "  std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*n*m);\n",
    "    \n",
    "  /* Determine mean of column vectors of input data matrix */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY0;\n",
    "      for (j = 0; j < _PB_N; j++) {\n",
    "        POLYBENCH_VAR_BODY1; \n",
    "      }\n",
    "      POLYBENCH_VAR_BODY2;\n",
    "  }\n",
    "\n",
    "  /* Center the column vectors. */\n",
    "  for (j = 0; j < _PB_N; j++) {\n",
    "    for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY3;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /* Calculate the m * m covariance matrix. */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "    for (k = i; k < _PB_M; k++) { // note this iteration space k is variable dependent on i\n",
    "      POLYBENCH_VAR_BODY4;\n",
    "      for (j = 0; j < _PB_N; j++) {\n",
    "\t    POLYBENCH_VAR_BODY5;\n",
    "      }\n",
    "      POLYBENCH_VAR_BODY6\n",
    "    }\n",
    "  }\n",
    "    \n",
    "  rajaperf::detail::deallocData(ldata, (rajaperf::VariantID)0);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106075f-67ec-4329-80dc-6c2acd780b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f284a-5846-4eba-a0a7-dce70e57baab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## setup lamdba seq to make it easier to code up the RAJA seq variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779b8c9-7234-4525-851b-0cd75f8dd4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "void kernel_cov_lambda(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "    int i, j, k;\n",
    "    rajaperf::Real_ptr ldata;\n",
    "    rajaperf::detail::allocData(ldata,m*n,RAJA::DATA_ALIGN,(rajaperf::VariantID)0);\n",
    "    std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*m*n);\n",
    "    double float_n = n;\n",
    "    \n",
    "    using Index_type = RAJA::Index_type;\n",
    "    using Real_type = RAJA::Real_type;\n",
    "    \n",
    "    auto poly_var_base_lam0 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY0;\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam1 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY1;\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam2 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY2;\n",
    "    };\n",
    "  \n",
    "    auto poly_var_base_lam3 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY3;\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam4 = [=] (Index_type i, Index_type k) {\n",
    "      POLYBENCH_VAR_BODY4;\n",
    "    };\n",
    "\n",
    "    auto poly_var_base_lam5 = [=] (Index_type i, Index_type j, Index_type k) {\n",
    "      POLYBENCH_VAR_BODY5;\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam6 = [=] (Index_type i, Index_type k) {\n",
    "      POLYBENCH_VAR_BODY6;\n",
    "    };\n",
    "\n",
    "    for(Index_type i = 0; i < m; ++i) {\n",
    "        poly_var_base_lam0(i);\n",
    "        for(Index_type j = 0; j < n; ++j) {\n",
    "            poly_var_base_lam1(i,j);\n",
    "        }\n",
    "        poly_var_base_lam2(i);\n",
    "    }\n",
    "    for(Index_type j = 0; j < n; ++j) {\n",
    "        for(Index_type i = 0; i < m; ++i) {\n",
    "            poly_var_base_lam3(i,j);\n",
    "        }\n",
    "    }\n",
    "#if 1\n",
    "    for(Index_type i = 0; i < m; ++i) {\n",
    "        for(Index_type k = i; k < m; ++k) {\n",
    "            poly_var_base_lam4(i,k);\n",
    "            for(Index_type j = 0; j < n; ++j) {\n",
    "                poly_var_base_lam5(i,j,k);\n",
    "            }\n",
    "            poly_var_base_lam6(i,k);\n",
    "        }\n",
    "    }\n",
    "#endif                \n",
    "    rajaperf::detail::deallocData(ldata, (rajaperf::VariantID)0);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1daa7c3-7389-4035-ab4b-27c7e19a5a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov_lambda(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53275e2-2788-49f6-8471-f4cef13f5f92",
   "metadata": {},
   "source": [
    "## setup RAJA views and RAJA lambda bodies in terms of the RAJA views\n",
    "The cell below illustrates how to setup a view with a simple 2D layout type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb5083-6e36-4fea-bb4e-d8acdf439599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "int L=2;\n",
    "\n",
    "double* A = new double [L * L];\n",
    "\n",
    "RAJA::View<double,RAJA::Layout<2> > Aview(A, L, L);\n",
    "Aview(0,0) = 0.0;\n",
    "Aview(0,1) = 1.0;\n",
    "Aview(1,0) = 2.0;\n",
    "Aview(1,1) = 3.0;\n",
    "for(int i = 0; i < L; ++i) {\n",
    "    for(int j = 0; j < L; ++j) {\n",
    "      printf(\"%p \",&Aview(i,j));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867502f-60e7-4664-90c3-0a23f145adc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template <typename T>\n",
    "void printValues(T* C, int N)\n",
    "{\n",
    "  for (int i = 0; i < N; ++i) {\n",
    "    std::cout << \"array[\" << i << \"] = \" << C[i] << std::endl;\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d61085-7b85-4d72-aa93-ca7fea4b8c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define POLYBENCH_VAR_VIEWS_RAJA \\\n",
    "  using VIEW_1 = RAJA::View<Real_type, RAJA::Layout<1> >; \\\n",
    "  using VIEW_2 = RAJA::View<Real_type, RAJA::Layout<2> >; \\\n",
    "  VIEW_1 meanview(mean,m); \\\n",
    "  VIEW_2 dataview(ldata,m,n); \\\n",
    "  VIEW_2 symmatview(symmat,m,m);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY0_RAJA \\\n",
    "  meanview(j) = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY1_RAJA \\\n",
    "  meanview(j) += dataview(i,j);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY2_RAJA \\\n",
    "  meanview(j) /= float_n;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY3_RAJA \\\n",
    "  dataview(i,j) -= meanview(j);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY4_RAJA \\\n",
    "  symmatview(j1,j2) = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY5_RAJA \\\n",
    "  symmatview(j1,j2) += dataview(i,j1) * dataview(i,j2);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY6_RAJA \\\n",
    "  symmatview(j2,j1) = symmatview(j1,j2);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51777b7c-c298-4114-a100-a9eb924085a2",
   "metadata": {},
   "source": [
    "## setup a RAJA Seq function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2d852-4b0d-4c41-99de-684c6d786dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "void kernel_cov_raja(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "#if 1\n",
    "    using Index_type = RAJA::Index_type;\n",
    "    using Real_type = RAJA::Real_type;\n",
    "    //Index_type i,j,k;\n",
    "    rajaperf::Real_ptr ldata;\n",
    "    rajaperf::detail::allocData(ldata,m*n,RAJA::DATA_ALIGN,(rajaperf::VariantID)0);\n",
    "    std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*m*n);\n",
    "#endif\n",
    "    double float_n = n;\n",
    "   \n",
    "    #define POLYBENCH_VAR_VIEWS_RAJA \\\n",
    "      using VIEW_1 = RAJA::View<Real_type, RAJA::Layout<1> >; \\\n",
    "      using VIEW_2 = RAJA::View<Real_type, RAJA::Layout<2> >; \\\n",
    "      VIEW_1 meanview(mean,m); \\\n",
    "      VIEW_2 dataview(ldata,n,m); \\\n",
    "      VIEW_2 symmatview(symmat,m,m);\n",
    "    \n",
    "    POLYBENCH_VAR_VIEWS_RAJA;\n",
    "\n",
    "    //RAJA::View<Real_type, RAJA::Layout<1> > meanview(mean,m);\n",
    "    //RAJA::View<Real_type, RAJA::Layout<2> > dataview(ldata,n,m);\n",
    "    //RAJA::View<Real_type, RAJA::Layout<2> > symmatview(symmat,m,m);\n",
    "\n",
    "    auto poly_var_base_lam0 = [=] (Index_type i) {\n",
    "        meanview(i) = 0.0;\n",
    "    };\n",
    "    \n",
    "   auto poly_var_base_lam1 = [=] (Index_type i, Index_type j) {\n",
    "       meanview(i) += dataview(j,i);\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam2 = [=] (Index_type i) {\n",
    "        meanview(i) /= float_n;\n",
    "    };\n",
    "  \n",
    "    auto poly_var_base_lam3 = [=] (Index_type i, Index_type j) {\n",
    "        dataview(j,i) -= meanview(i);\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam4 = [=] (Index_type i) {\n",
    "        for(Index_type kk=i; kk < m; kk++) {\n",
    "          symmatview(i,kk) = 0.0;\n",
    "          for(Index_type jj=0; jj<n; jj++) {\n",
    "              symmatview(i,kk) += dataview(jj,i) * dataview(jj,kk);\n",
    "          }\n",
    "          symmatview(kk,i) = symmatview(i,kk);\n",
    "        }\n",
    "    };\n",
    "\n",
    "     using EXECPOL = RAJA::KernelPolicy<\n",
    "                        RAJA::statement::For<0, RAJA::loop_exec,    // over m\n",
    "                          RAJA::statement::Lambda<0, RAJA::Segs<0> >,  // i\n",
    "                          RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                            RAJA::statement::Lambda<1, RAJA::Segs<0,1> > // i,j\n",
    "                          >,\n",
    "                          RAJA::statement::Lambda<2, RAJA::Segs<0> > // i\n",
    "                        >,\n",
    "                        RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                          RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                            RAJA::statement::Lambda<3, RAJA::Segs<0,1> > // i,j\n",
    "                          >\n",
    "                        >,\n",
    "                        RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                          RAJA::statement::Lambda<4, RAJA::Segs<0> >\n",
    "                        >\n",
    "                      >;  \n",
    " \n",
    "   RAJA::kernel_param<EXECPOL>(\n",
    "          RAJA::make_tuple(RAJA::RangeSegment{0,m}, RAJA::RangeSegment{0,n}),\n",
    "          RAJA::tuple<double>{0.0}, // we're using kernel_param for the convenience of specifying iteration spaces (Segs), so we need this param tuple\n",
    "          poly_var_base_lam0,\n",
    "          poly_var_base_lam1,\n",
    "          poly_var_base_lam2,\n",
    "          poly_var_base_lam3,\n",
    "          poly_var_base_lam4\n",
    "        );\n",
    " \n",
    "  rajaperf::detail::deallocData(ldata, (rajaperf::VariantID)0);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43797b88-e7d5-4ed5-923c-53d6446ce82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov_raja(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80e0dd-06b4-4cbe-87f6-de7add7e1187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17-omp",
   "language": "C++17",
   "name": "xcpp17-omp"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
